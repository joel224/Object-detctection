{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA5f8N5c13tHK/fO8uM6KP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joel224/Object-detctection/blob/main/myprj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivDwnum7aaw6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "06e38cd4",
        "outputId": "1308240b-c33f-4c58-b1e3-43b2577897d0"
      },
      "source": [
        "!pip install onnxruntime onnx"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.18.0 onnxruntime-1.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55e0f50a",
        "outputId": "fdac5c39-db3d-4a8c-b69a-b577df6cb585"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "86578ef9",
        "outputId": "ef687f9c-c830-4ae2-b968-827381fb77f9"
      },
      "source": [
        "!pip install easyocr\n",
        "!pip install torch==2.3.0+cpu torchvision==0.18.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.3.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.6.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.1)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.11.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.3.0+cpu\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torch-2.3.0%2Bcpu-cp311-cp311-linux_x86_64.whl (190.4 MB)\n",
            "Collecting torchvision==0.18.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.18.0%2Bcpu-cp311-cp311-linux_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0+cpu) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0+cpu) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0+cpu) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0+cpu) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0+cpu) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0+cpu) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0+cpu) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0+cpu) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0+cpu) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0+cpu) (1.3.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.3.0+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.3.0+cpu torchvision-0.18.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7345a20d"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the necessary subfolders within the 'DS' folder on Google Drive if they don't already exist.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "097fc788",
        "outputId": "7c5eda4f-3fbb-405e-fd39-94c22d9cd188"
      },
      "source": [
        "!pip install easyocr\n",
        "!pip install torch==2.3.0+cpu torchvision==0.18.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.3.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.1)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.2.0)\n",
            "Collecting sympy==1.13.1 (from torch->easyocr)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, sympy, ninja, easyocr\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "onnxslim 0.1.61 requires sympy>=1.13.3, but you have sympy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed easyocr-1.7.2 ninja-1.11.1.4 pyclipper-1.3.0.post6 python-bidi-0.6.6 sympy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sympy"
                ]
              },
              "id": "6019db8275554dbc99b039bc2c5c9eb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.3.0+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.3.0%2Bcpu-cp311-cp311-linux_x86_64.whl (190.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.4/190.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87154d25",
        "outputId": "326e1dc0-01b9-4565-a25b-9893f1fa6c10"
      },
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/My Drive/DS'\n",
        "subfolders = [\"raw_images\", \"annotations\", \"trained_models\", \"processed_output\"]\n",
        "\n",
        "for folder in subfolders:\n",
        "    full_path = os.path.join(base_path, folder)\n",
        "    if not os.path.exists(full_path):\n",
        "        os.makedirs(full_path)\n",
        "        print(f\"Created folder: {full_path}\")\n",
        "    else:\n",
        "        print(f\"Folder already exists: {full_path}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folder: /content/drive/My Drive/DS/raw_images\n",
            "Created folder: /content/drive/My Drive/DS/annotations\n",
            "Created folder: /content/drive/My Drive/DS/trained_models\n",
            "Created folder: /content/drive/My Drive/DS/processed_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "85b05f2c",
        "outputId": "eb8cba22-fdc1-4f28-98a4-44bd2a3c8d4c"
      },
      "source": [
        "!pip install ultralytics"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.170)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d167dc2",
        "outputId": "1052f887-2534-4cf9-c13b-e7dc2bc90ab3"
      },
      "source": [
        "# Download and unzip the dataset (Original)\n",
        "!curl -L \"https://universe.roboflow.com/ds/OUYQDZKZAN?key=UK4mQpwlH\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "\n",
        "# Download and unzip additional dataset 1\n",
        "!curl -L \"https://universe.roboflow.com/ds/Vd3ua3FtHC?key=SQ2w8hPDRg\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "\n",
        "# Download and unzip additional dataset 2\n",
        "!curl -L \"https://universe.roboflow.com/ds/EtuT0Xwpue?key=BvMruMYWUU\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "\n",
        "# Install ultralytics\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    29  100    29    0     0    129      0 --:--:-- --:--:-- --:--:--   129\n",
            "Archive:  roboflow.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of roboflow.zip or\n",
            "        roboflow.zip.zip, and cannot find roboflow.zip.ZIP, period.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   903  100   903    0     0   3576      0 --:--:-- --:--:-- --:--:--  3583\n",
            "100 11.8M  100 11.8M    0     0  5443k      0  0:00:02  0:00:02 --:--:-- 7990k\n",
            "Archive:  roboflow.zip\n",
            "replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: README.dataset.txt      \n",
            "replace README.roboflow.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: README.roboflow.txt     \n",
            "replace data.yaml? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data.yaml               \n",
            " extracting: test/images/g1p35c8s49na1_jpg.rf.3fbaea5b617329c88b446a561cbbe7cf.jpg  \n",
            " extracting: test/images/nf94pwed89ma1_jpg.rf.ec816e894cbf00d54c5201d12a43b2f9.jpg  \n",
            " extracting: test/images/pb23izcgs8na1_jpg.rf.2a898f909123ba7aeca1e323d1b4706c.jpg  \n",
            " extracting: test/images/qwmd0qj54tla1_jpg.rf.9ff6494e4346b78255211bb9a4321cdd.jpg  \n",
            " extracting: test/images/s63feb9suiha1_jpg.rf.be622b61b6c0a8e157afc4d5b4c6aeaa.jpg  \n",
            " extracting: test/images/unx8gr3itzka1_jpg.rf.a98c5b29f4d5f2a34d0d229f7cbda1f2.jpg  \n",
            "  inflating: test/labels/g1p35c8s49na1_jpg.rf.3fbaea5b617329c88b446a561cbbe7cf.txt  \n",
            "  inflating: test/labels/nf94pwed89ma1_jpg.rf.ec816e894cbf00d54c5201d12a43b2f9.txt  \n",
            "  inflating: test/labels/pb23izcgs8na1_jpg.rf.2a898f909123ba7aeca1e323d1b4706c.txt  \n",
            "  inflating: test/labels/qwmd0qj54tla1_jpg.rf.9ff6494e4346b78255211bb9a4321cdd.txt  \n",
            "  inflating: test/labels/s63feb9suiha1_jpg.rf.be622b61b6c0a8e157afc4d5b4c6aeaa.txt  \n",
            "  inflating: test/labels/unx8gr3itzka1_jpg.rf.a98c5b29f4d5f2a34d0d229f7cbda1f2.txt  \n",
            " extracting: train/images/ITbrHXGkkzaOSsNJwFxm0Lk-OAiTUxsq1LdRgbnpPJE_jpg.rf.973dd6243638ab7b9348b59cb72099fe.jpg  \n",
            " extracting: train/images/ITbrHXGkkzaOSsNJwFxm0Lk-OAiTUxsq1LdRgbnpPJE_jpg.rf.b9770275735d1703d6056cde1199a575.jpg  \n",
            " extracting: train/images/ITbrHXGkkzaOSsNJwFxm0Lk-OAiTUxsq1LdRgbnpPJE_jpg.rf.f3c95020ab0d7a98f47ce03dd4d85b88.jpg  \n",
            " extracting: train/images/dzmsrsx9vyna1_jpg.rf.7a2ee6ffe58b62ea0ae6bcb4461856c2.jpg  \n",
            " extracting: train/images/dzmsrsx9vyna1_jpg.rf.a6cd5583422eedd05a42260c6464d1c4.jpg  \n",
            " extracting: train/images/dzmsrsx9vyna1_jpg.rf.c77db683c3d32b18382cbaf6a5eca808.jpg  \n",
            " extracting: train/images/e1hzdr4u5nja1_jpg.rf.a08f03cfa5902781deccf1cbfe9e836c.jpg  \n",
            " extracting: train/images/e1hzdr4u5nja1_jpg.rf.b7fe0bf4ffc53ec85087a5b916f5eeb8.jpg  \n",
            " extracting: train/images/e1hzdr4u5nja1_jpg.rf.bcd8e801dbf8857ee9ec282382efd642.jpg  \n",
            " extracting: train/images/hto0sjzxrfja1_jpg.rf.1f7bf25614c5128df6d009f9b65c3d4a.jpg  \n",
            " extracting: train/images/hto0sjzxrfja1_jpg.rf.412db85d12bb5ad10318d286347210c7.jpg  \n",
            " extracting: train/images/hto0sjzxrfja1_jpg.rf.fc441022d54a405db15b883f97b76700.jpg  \n",
            " extracting: train/images/jZwxHv3L5WzAWzQNFENl5yU3rSDx1fZozL7bfoV36j8_jpg.rf.7d61a8a91f49f0e0853676c4fa39e43c.jpg  \n",
            " extracting: train/images/jZwxHv3L5WzAWzQNFENl5yU3rSDx1fZozL7bfoV36j8_jpg.rf.ca9174f1357c4444e524ba72949f3061.jpg  \n",
            " extracting: train/images/jZwxHv3L5WzAWzQNFENl5yU3rSDx1fZozL7bfoV36j8_jpg.rf.d2e54e5d4d091c158748b69e1daf369c.jpg  \n",
            " extracting: train/images/jdgdp12a7qea1_jpg.rf.36acc6eaa8d7e7198b927944cb02c3fa.jpg  \n",
            " extracting: train/images/jdgdp12a7qea1_jpg.rf.890340a13994cefc522a5f2db426c9e9.jpg  \n",
            " extracting: train/images/jdgdp12a7qea1_jpg.rf.995ad1520c62f254f21b61025b425127.jpg  \n",
            " extracting: train/images/jxtpts0yzaea1_jpg.rf.45a573a5a4bae4d873478bca150213e4.jpg  \n",
            " extracting: train/images/jxtpts0yzaea1_jpg.rf.a0c3aaaecedc5fc918c5f2af7a49f92d.jpg  \n",
            " extracting: train/images/jxtpts0yzaea1_jpg.rf.d48ed1a9faf24022795111dc9242a703.jpg  \n",
            " extracting: train/images/l8uqlisis0fa1_jpg.rf.17b99dd64ca1f64cb6a29cdcaa7cde05.jpg  \n",
            " extracting: train/images/l8uqlisis0fa1_jpg.rf.8255f01b9207ce82d233725c510e0dde.jpg  \n",
            " extracting: train/images/l8uqlisis0fa1_jpg.rf.d5c2b4bb6c6bf58c2911dc3d084554a0.jpg  \n",
            " extracting: train/images/lsibmb1um6ea1_jpg.rf.a1ab1a85dc9a714f6a044fe7dfa163a9.jpg  \n",
            " extracting: train/images/lsibmb1um6ea1_jpg.rf.bdf601c3d4513ff4aba1d77addd9de3a.jpg  \n",
            " extracting: train/images/lsibmb1um6ea1_jpg.rf.f093ba1cb490a3ee1a511185e1fa30e8.jpg  \n",
            " extracting: train/images/mfm6fz0yvela1_jpg.rf.0601ecfea4e0410c8df4720d748b41cc.jpg  \n",
            " extracting: train/images/mfm6fz0yvela1_jpg.rf.22441839b845e6e62dbf380478d9f5e9.jpg  \n",
            " extracting: train/images/mfm6fz0yvela1_jpg.rf.f0dbca2d3b98f11b92d6fdee1d978180.jpg  \n",
            " extracting: train/images/mtg6u7luzmga1_jpg.rf.06cbb3d6a41cc3fc357b2263816e1654.jpg  \n",
            " extracting: train/images/mtg6u7luzmga1_jpg.rf.6da479f3f0e49b5dd20aa1242b778af7.jpg  \n",
            " extracting: train/images/mtg6u7luzmga1_jpg.rf.acb9dc8bf91f0c54c9645ea77fe799ef.jpg  \n",
            " extracting: train/images/oakiqj6oa0ha1_jpg.rf.2cff147ebe5f784170ec46c70fff385a.jpg  \n",
            " extracting: train/images/oakiqj6oa0ha1_jpg.rf.3348ad0da85e6c87db0215cd1f29ee58.jpg  \n",
            " extracting: train/images/oakiqj6oa0ha1_jpg.rf.626472fa7aeb30704b3c9cec4f0b408f.jpg  \n",
            " extracting: train/images/ocrpvqiej7fa1_jpg.rf.c0d2718524e04ab276bea1be9c4b6d73.jpg  \n",
            " extracting: train/images/ocrpvqiej7fa1_jpg.rf.e3d1d3f2d36080e9da4d5d2e5cfdc6c7.jpg  \n",
            " extracting: train/images/ocrpvqiej7fa1_jpg.rf.f782e5cc3ab6169755f78d7ffdd533d5.jpg  \n",
            " extracting: train/images/og0495u1j0ca1_jpg.rf.65b1287afc23ca540dd8ec8a78478621.jpg  \n",
            " extracting: train/images/og0495u1j0ca1_jpg.rf.6998702303adc6d39f9da635f9817041.jpg  \n",
            " extracting: train/images/og0495u1j0ca1_jpg.rf.b0ee1c96fabddbaf7f6fe69f4babc7a7.jpg  \n",
            " extracting: train/images/p4smg0eq3gna1_jpg.rf.48d78bc8bc8a906250f1d9ac58489f94.jpg  \n",
            " extracting: train/images/p4smg0eq3gna1_jpg.rf.7bcd5002cfdef6398a7ff1b12db87690.jpg  \n",
            " extracting: train/images/p4smg0eq3gna1_jpg.rf.7dc60f98320bbfcc28963df1f248e47d.jpg  \n",
            " extracting: train/images/pxuvds6zr5da1_jpg.rf.2f2065907f1bebb30f862702dba3e8ee.jpg  \n",
            " extracting: train/images/pxuvds6zr5da1_jpg.rf.660cbe841ae68b51c747422dd774f785.jpg  \n",
            " extracting: train/images/pxuvds6zr5da1_jpg.rf.a3bc33526c0b8dc04101e5b5dca550af.jpg  \n",
            " extracting: train/images/pyyw6nfbhbha1_jpg.rf.05c63f9f73ee352a64959a9e83fc0552.jpg  \n",
            " extracting: train/images/pyyw6nfbhbha1_jpg.rf.64754feb338c975f4f28a48101bcaf7f.jpg  \n",
            " extracting: train/images/pyyw6nfbhbha1_jpg.rf.fe590610b221201b3dbcb49fddf096e3.jpg  \n",
            " extracting: train/images/qp3ab0qrdbga1_jpg.rf.36bcc50f6e7f1d0534469ca876f7467e.jpg  \n",
            " extracting: train/images/qp3ab0qrdbga1_jpg.rf.a0dfbdaa16d278a4022e987ec779300f.jpg  \n",
            " extracting: train/images/qp3ab0qrdbga1_jpg.rf.a850c3ab739789ae7309ad40a926ebe5.jpg  \n",
            " extracting: train/images/r9ko4kqc3saa1_jpg.rf.9c98c2cfbf7511847e1e9a252b847f4f.jpg  \n",
            " extracting: train/images/r9ko4kqc3saa1_jpg.rf.9e84d78a6555b84effcd2c0dcdb9670e.jpg  \n",
            " extracting: train/images/r9ko4kqc3saa1_jpg.rf.d4547361bedf5d34e201fec75412af44.jpg  \n",
            " extracting: train/images/sf7dm6lymvja1_jpg.rf.3cf0d6e805b000a8a095a32dd540eff0.jpg  \n",
            " extracting: train/images/sf7dm6lymvja1_jpg.rf.68d22fcc9eb910d62769b8401ee256f6.jpg  \n",
            " extracting: train/images/sf7dm6lymvja1_jpg.rf.c919ca11fe086b9f570f5076866fa90f.jpg  \n",
            " extracting: train/images/ssc0y5drl1ja1_jpg.rf.7a2a83b317db7953640a7ce2659638df.jpg  \n",
            " extracting: train/images/ssc0y5drl1ja1_jpg.rf.9446b49288358017d0eb3ab6291bb756.jpg  \n",
            " extracting: train/images/ssc0y5drl1ja1_jpg.rf.b465c3c84c8f3de31b1ddef1043dd340.jpg  \n",
            " extracting: train/images/sxj13v9gunea1_jpg.rf.07f51837f4442710c7ba1ce9a26a1419.jpg  \n",
            " extracting: train/images/sxj13v9gunea1_jpg.rf.36c22d1137aef8df4e1bba0e46a51413.jpg  \n",
            " extracting: train/images/sxj13v9gunea1_jpg.rf.cc0fa0f8d54c231f9c1e76dcdd930f63.jpg  \n",
            " extracting: train/images/u0f044lfh5da1_jpg.rf.1630dd85db9b1781eb4581ae104e5c02.jpg  \n",
            " extracting: train/images/u0f044lfh5da1_jpg.rf.77a56e0b68a9ef79c46d458ade1f22ac.jpg  \n",
            " extracting: train/images/u0f044lfh5da1_jpg.rf.8f7bb17b3e4e225b490d48a129cdede7.jpg  \n",
            " extracting: train/images/ve3k2giaenna1_jpg.rf.2d0149c64ceedd091f355363d151d870.jpg  \n",
            " extracting: train/images/ve3k2giaenna1_jpg.rf.bc8dfd0817d3bb40fd74df37f48a2119.jpg  \n",
            " extracting: train/images/ve3k2giaenna1_jpg.rf.fcfb23c216c2107f5c735fd3d6b58c62.jpg  \n",
            " extracting: train/images/wWQCsmStWRTD4UklG0SYirJjXQ_cKUKE8osAv3s4nyE_jpg.rf.3dacd39786e7ca05ea1c685f32cd6b60.jpg  \n",
            " extracting: train/images/wWQCsmStWRTD4UklG0SYirJjXQ_cKUKE8osAv3s4nyE_jpg.rf.584396c565a61deb83de5766aac3b328.jpg  \n",
            " extracting: train/images/wWQCsmStWRTD4UklG0SYirJjXQ_cKUKE8osAv3s4nyE_jpg.rf.dcf5e153f4fd4cfea64b9e9e7fab395a.jpg  \n",
            " extracting: train/images/wqbii1d0wiha1_jpg.rf.89c596ea28eba75e691a152c5df37641.jpg  \n",
            " extracting: train/images/wqbii1d0wiha1_jpg.rf.a01a6e3668fc2f797d0d40dd2b61b4d5.jpg  \n",
            " extracting: train/images/wqbii1d0wiha1_jpg.rf.ae9d0258bc5b88041dab9642643bc8c4.jpg  \n",
            " extracting: train/images/x95jva8vsfha1_jpg.rf.47f0264e4487d3b896949ca71601a17a.jpg  \n",
            " extracting: train/images/x95jva8vsfha1_jpg.rf.4845116e443f938b644b55e7f6ce9161.jpg  \n",
            " extracting: train/images/x95jva8vsfha1_jpg.rf.da76ad24d881720bb68460afa161fba0.jpg  \n",
            " extracting: train/images/xeeej1a7mvla1_jpg.rf.375c7605db7f1742858cdd33c6924543.jpg  \n",
            " extracting: train/images/xeeej1a7mvla1_jpg.rf.3aee85e8a6c4c8f5d58e1339f0bfe069.jpg  \n",
            " extracting: train/images/xeeej1a7mvla1_jpg.rf.b579eb234b73ca57d3668fd9efeec67b.jpg  \n",
            " extracting: train/images/xyiyazotn9ga1_jpg.rf.271d08ea0fae14865257b7d2ce009227.jpg  \n",
            " extracting: train/images/xyiyazotn9ga1_jpg.rf.d3f80579322e0b53fea58c2b6f63ea7c.jpg  \n",
            " extracting: train/images/xyiyazotn9ga1_jpg.rf.e856b22bbd037e76745a729755c245c9.jpg  \n",
            " extracting: train/images/y6ng4evbboba1_jpg.rf.1fb5fd17d123d0c0158939404ebf16d0.jpg  \n",
            " extracting: train/images/y6ng4evbboba1_jpg.rf.359cc4ce079f5b3e2c6fc513f4eb0b3b.jpg  \n",
            " extracting: train/images/y6ng4evbboba1_jpg.rf.8b5e8a35f403c102895c944c6a605451.jpg  \n",
            " extracting: train/images/z9bype9vpuga1_jpg.rf.201f89b8686a4a06d19f1d2f7deaa529.jpg  \n",
            " extracting: train/images/z9bype9vpuga1_jpg.rf.d2ad1445ce7427f5422d2acb59685952.jpg  \n",
            " extracting: train/images/z9bype9vpuga1_jpg.rf.e9048f96df9ceadaa1cd854be6d45c6b.jpg  \n",
            " extracting: train/images/zr2m1dok9tja1_jpg.rf.227b6da1e1538ed8be795ee6c3c1e453.jpg  \n",
            " extracting: train/images/zr2m1dok9tja1_jpg.rf.382b9fa2818761f1a8133836c54dd7c8.jpg  \n",
            " extracting: train/images/zr2m1dok9tja1_jpg.rf.a9ff12aea109494001b697924ae287e2.jpg  \n",
            "  inflating: train/labels/ITbrHXGkkzaOSsNJwFxm0Lk-OAiTUxsq1LdRgbnpPJE_jpg.rf.973dd6243638ab7b9348b59cb72099fe.txt  \n",
            "  inflating: train/labels/ITbrHXGkkzaOSsNJwFxm0Lk-OAiTUxsq1LdRgbnpPJE_jpg.rf.b9770275735d1703d6056cde1199a575.txt  \n",
            "  inflating: train/labels/ITbrHXGkkzaOSsNJwFxm0Lk-OAiTUxsq1LdRgbnpPJE_jpg.rf.f3c95020ab0d7a98f47ce03dd4d85b88.txt  \n",
            "  inflating: train/labels/dzmsrsx9vyna1_jpg.rf.7a2ee6ffe58b62ea0ae6bcb4461856c2.txt  \n",
            "  inflating: train/labels/dzmsrsx9vyna1_jpg.rf.a6cd5583422eedd05a42260c6464d1c4.txt  \n",
            "  inflating: train/labels/dzmsrsx9vyna1_jpg.rf.c77db683c3d32b18382cbaf6a5eca808.txt  \n",
            "  inflating: train/labels/e1hzdr4u5nja1_jpg.rf.a08f03cfa5902781deccf1cbfe9e836c.txt  \n",
            "  inflating: train/labels/e1hzdr4u5nja1_jpg.rf.b7fe0bf4ffc53ec85087a5b916f5eeb8.txt  \n",
            "  inflating: train/labels/e1hzdr4u5nja1_jpg.rf.bcd8e801dbf8857ee9ec282382efd642.txt  \n",
            "  inflating: train/labels/hto0sjzxrfja1_jpg.rf.1f7bf25614c5128df6d009f9b65c3d4a.txt  \n",
            "  inflating: train/labels/hto0sjzxrfja1_jpg.rf.412db85d12bb5ad10318d286347210c7.txt  \n",
            "  inflating: train/labels/hto0sjzxrfja1_jpg.rf.fc441022d54a405db15b883f97b76700.txt  \n",
            "  inflating: train/labels/jZwxHv3L5WzAWzQNFENl5yU3rSDx1fZozL7bfoV36j8_jpg.rf.7d61a8a91f49f0e0853676c4fa39e43c.txt  \n",
            "  inflating: train/labels/jZwxHv3L5WzAWzQNFENl5yU3rSDx1fZozL7bfoV36j8_jpg.rf.ca9174f1357c4444e524ba72949f3061.txt  \n",
            "  inflating: train/labels/jZwxHv3L5WzAWzQNFENl5yU3rSDx1fZozL7bfoV36j8_jpg.rf.d2e54e5d4d091c158748b69e1daf369c.txt  \n",
            "  inflating: train/labels/jdgdp12a7qea1_jpg.rf.36acc6eaa8d7e7198b927944cb02c3fa.txt  \n",
            "  inflating: train/labels/jdgdp12a7qea1_jpg.rf.890340a13994cefc522a5f2db426c9e9.txt  \n",
            "  inflating: train/labels/jdgdp12a7qea1_jpg.rf.995ad1520c62f254f21b61025b425127.txt  \n",
            "  inflating: train/labels/jxtpts0yzaea1_jpg.rf.45a573a5a4bae4d873478bca150213e4.txt  \n",
            "  inflating: train/labels/jxtpts0yzaea1_jpg.rf.a0c3aaaecedc5fc918c5f2af7a49f92d.txt  \n",
            "  inflating: train/labels/jxtpts0yzaea1_jpg.rf.d48ed1a9faf24022795111dc9242a703.txt  \n",
            "  inflating: train/labels/l8uqlisis0fa1_jpg.rf.17b99dd64ca1f64cb6a29cdcaa7cde05.txt  \n",
            "  inflating: train/labels/l8uqlisis0fa1_jpg.rf.8255f01b9207ce82d233725c510e0dde.txt  \n",
            "  inflating: train/labels/l8uqlisis0fa1_jpg.rf.d5c2b4bb6c6bf58c2911dc3d084554a0.txt  \n",
            "  inflating: train/labels/lsibmb1um6ea1_jpg.rf.a1ab1a85dc9a714f6a044fe7dfa163a9.txt  \n",
            "  inflating: train/labels/lsibmb1um6ea1_jpg.rf.bdf601c3d4513ff4aba1d77addd9de3a.txt  \n",
            "  inflating: train/labels/lsibmb1um6ea1_jpg.rf.f093ba1cb490a3ee1a511185e1fa30e8.txt  \n",
            "  inflating: train/labels/mfm6fz0yvela1_jpg.rf.0601ecfea4e0410c8df4720d748b41cc.txt  \n",
            "  inflating: train/labels/mfm6fz0yvela1_jpg.rf.22441839b845e6e62dbf380478d9f5e9.txt  \n",
            "  inflating: train/labels/mfm6fz0yvela1_jpg.rf.f0dbca2d3b98f11b92d6fdee1d978180.txt  \n",
            "  inflating: train/labels/mtg6u7luzmga1_jpg.rf.06cbb3d6a41cc3fc357b2263816e1654.txt  \n",
            "  inflating: train/labels/mtg6u7luzmga1_jpg.rf.6da479f3f0e49b5dd20aa1242b778af7.txt  \n",
            "  inflating: train/labels/mtg6u7luzmga1_jpg.rf.acb9dc8bf91f0c54c9645ea77fe799ef.txt  \n",
            "  inflating: train/labels/oakiqj6oa0ha1_jpg.rf.2cff147ebe5f784170ec46c70fff385a.txt  \n",
            "  inflating: train/labels/oakiqj6oa0ha1_jpg.rf.3348ad0da85e6c87db0215cd1f29ee58.txt  \n",
            "  inflating: train/labels/oakiqj6oa0ha1_jpg.rf.626472fa7aeb30704b3c9cec4f0b408f.txt  \n",
            "  inflating: train/labels/ocrpvqiej7fa1_jpg.rf.c0d2718524e04ab276bea1be9c4b6d73.txt  \n",
            "  inflating: train/labels/ocrpvqiej7fa1_jpg.rf.e3d1d3f2d36080e9da4d5d2e5cfdc6c7.txt  \n",
            "  inflating: train/labels/ocrpvqiej7fa1_jpg.rf.f782e5cc3ab6169755f78d7ffdd533d5.txt  \n",
            "  inflating: train/labels/og0495u1j0ca1_jpg.rf.65b1287afc23ca540dd8ec8a78478621.txt  \n",
            "  inflating: train/labels/og0495u1j0ca1_jpg.rf.6998702303adc6d39f9da635f9817041.txt  \n",
            "  inflating: train/labels/og0495u1j0ca1_jpg.rf.b0ee1c96fabddbaf7f6fe69f4babc7a7.txt  \n",
            "  inflating: train/labels/p4smg0eq3gna1_jpg.rf.48d78bc8bc8a906250f1d9ac58489f94.txt  \n",
            "  inflating: train/labels/p4smg0eq3gna1_jpg.rf.7bcd5002cfdef6398a7ff1b12db87690.txt  \n",
            "  inflating: train/labels/p4smg0eq3gna1_jpg.rf.7dc60f98320bbfcc28963df1f248e47d.txt  \n",
            "  inflating: train/labels/pxuvds6zr5da1_jpg.rf.2f2065907f1bebb30f862702dba3e8ee.txt  \n",
            "  inflating: train/labels/pxuvds6zr5da1_jpg.rf.660cbe841ae68b51c747422dd774f785.txt  \n",
            "  inflating: train/labels/pxuvds6zr5da1_jpg.rf.a3bc33526c0b8dc04101e5b5dca550af.txt  \n",
            "  inflating: train/labels/pyyw6nfbhbha1_jpg.rf.05c63f9f73ee352a64959a9e83fc0552.txt  \n",
            "  inflating: train/labels/pyyw6nfbhbha1_jpg.rf.64754feb338c975f4f28a48101bcaf7f.txt  \n",
            "  inflating: train/labels/pyyw6nfbhbha1_jpg.rf.fe590610b221201b3dbcb49fddf096e3.txt  \n",
            "  inflating: train/labels/qp3ab0qrdbga1_jpg.rf.36bcc50f6e7f1d0534469ca876f7467e.txt  \n",
            "  inflating: train/labels/qp3ab0qrdbga1_jpg.rf.a0dfbdaa16d278a4022e987ec779300f.txt  \n",
            "  inflating: train/labels/qp3ab0qrdbga1_jpg.rf.a850c3ab739789ae7309ad40a926ebe5.txt  \n",
            "  inflating: train/labels/r9ko4kqc3saa1_jpg.rf.9c98c2cfbf7511847e1e9a252b847f4f.txt  \n",
            "  inflating: train/labels/r9ko4kqc3saa1_jpg.rf.9e84d78a6555b84effcd2c0dcdb9670e.txt  \n",
            "  inflating: train/labels/r9ko4kqc3saa1_jpg.rf.d4547361bedf5d34e201fec75412af44.txt  \n",
            "  inflating: train/labels/sf7dm6lymvja1_jpg.rf.3cf0d6e805b000a8a095a32dd540eff0.txt  \n",
            "  inflating: train/labels/sf7dm6lymvja1_jpg.rf.68d22fcc9eb910d62769b8401ee256f6.txt  \n",
            "  inflating: train/labels/sf7dm6lymvja1_jpg.rf.c919ca11fe086b9f570f5076866fa90f.txt  \n",
            "  inflating: train/labels/ssc0y5drl1ja1_jpg.rf.7a2a83b317db7953640a7ce2659638df.txt  \n",
            "  inflating: train/labels/ssc0y5drl1ja1_jpg.rf.9446b49288358017d0eb3ab6291bb756.txt  \n",
            "  inflating: train/labels/ssc0y5drl1ja1_jpg.rf.b465c3c84c8f3de31b1ddef1043dd340.txt  \n",
            "  inflating: train/labels/sxj13v9gunea1_jpg.rf.07f51837f4442710c7ba1ce9a26a1419.txt  \n",
            "  inflating: train/labels/sxj13v9gunea1_jpg.rf.36c22d1137aef8df4e1bba0e46a51413.txt  \n",
            "  inflating: train/labels/sxj13v9gunea1_jpg.rf.cc0fa0f8d54c231f9c1e76dcdd930f63.txt  \n",
            "  inflating: train/labels/u0f044lfh5da1_jpg.rf.1630dd85db9b1781eb4581ae104e5c02.txt  \n",
            "  inflating: train/labels/u0f044lfh5da1_jpg.rf.77a56e0b68a9ef79c46d458ade1f22ac.txt  \n",
            "  inflating: train/labels/u0f044lfh5da1_jpg.rf.8f7bb17b3e4e225b490d48a129cdede7.txt  \n",
            "  inflating: train/labels/ve3k2giaenna1_jpg.rf.2d0149c64ceedd091f355363d151d870.txt  \n",
            "  inflating: train/labels/ve3k2giaenna1_jpg.rf.bc8dfd0817d3bb40fd74df37f48a2119.txt  \n",
            "  inflating: train/labels/ve3k2giaenna1_jpg.rf.fcfb23c216c2107f5c735fd3d6b58c62.txt  \n",
            "  inflating: train/labels/wWQCsmStWRTD4UklG0SYirJjXQ_cKUKE8osAv3s4nyE_jpg.rf.3dacd39786e7ca05ea1c685f32cd6b60.txt  \n",
            "  inflating: train/labels/wWQCsmStWRTD4UklG0SYirJjXQ_cKUKE8osAv3s4nyE_jpg.rf.584396c565a61deb83de5766aac3b328.txt  \n",
            "  inflating: train/labels/wWQCsmStWRTD4UklG0SYirJjXQ_cKUKE8osAv3s4nyE_jpg.rf.dcf5e153f4fd4cfea64b9e9e7fab395a.txt  \n",
            "  inflating: train/labels/wqbii1d0wiha1_jpg.rf.89c596ea28eba75e691a152c5df37641.txt  \n",
            "  inflating: train/labels/wqbii1d0wiha1_jpg.rf.a01a6e3668fc2f797d0d40dd2b61b4d5.txt  \n",
            "  inflating: train/labels/wqbii1d0wiha1_jpg.rf.ae9d0258bc5b88041dab9642643bc8c4.txt  \n",
            "  inflating: train/labels/x95jva8vsfha1_jpg.rf.47f0264e4487d3b896949ca71601a17a.txt  \n",
            "  inflating: train/labels/x95jva8vsfha1_jpg.rf.4845116e443f938b644b55e7f6ce9161.txt  \n",
            "  inflating: train/labels/x95jva8vsfha1_jpg.rf.da76ad24d881720bb68460afa161fba0.txt  \n",
            "  inflating: train/labels/xeeej1a7mvla1_jpg.rf.375c7605db7f1742858cdd33c6924543.txt  \n",
            "  inflating: train/labels/xeeej1a7mvla1_jpg.rf.3aee85e8a6c4c8f5d58e1339f0bfe069.txt  \n",
            "  inflating: train/labels/xeeej1a7mvla1_jpg.rf.b579eb234b73ca57d3668fd9efeec67b.txt  \n",
            "  inflating: train/labels/xyiyazotn9ga1_jpg.rf.271d08ea0fae14865257b7d2ce009227.txt  \n",
            "  inflating: train/labels/xyiyazotn9ga1_jpg.rf.d3f80579322e0b53fea58c2b6f63ea7c.txt  \n",
            "  inflating: train/labels/xyiyazotn9ga1_jpg.rf.e856b22bbd037e76745a729755c245c9.txt  \n",
            "  inflating: train/labels/y6ng4evbboba1_jpg.rf.1fb5fd17d123d0c0158939404ebf16d0.txt  \n",
            "  inflating: train/labels/y6ng4evbboba1_jpg.rf.359cc4ce079f5b3e2c6fc513f4eb0b3b.txt  \n",
            "  inflating: train/labels/y6ng4evbboba1_jpg.rf.8b5e8a35f403c102895c944c6a605451.txt  \n",
            "  inflating: train/labels/z9bype9vpuga1_jpg.rf.201f89b8686a4a06d19f1d2f7deaa529.txt  \n",
            "  inflating: train/labels/z9bype9vpuga1_jpg.rf.d2ad1445ce7427f5422d2acb59685952.txt  \n",
            "  inflating: train/labels/z9bype9vpuga1_jpg.rf.e9048f96df9ceadaa1cd854be6d45c6b.txt  \n",
            "  inflating: train/labels/zr2m1dok9tja1_jpg.rf.227b6da1e1538ed8be795ee6c3c1e453.txt  \n",
            "  inflating: train/labels/zr2m1dok9tja1_jpg.rf.382b9fa2818761f1a8133836c54dd7c8.txt  \n",
            "  inflating: train/labels/zr2m1dok9tja1_jpg.rf.a9ff12aea109494001b697924ae287e2.txt  \n",
            " extracting: valid/images/f3qb1vrj1yoa1_jpg.rf.de8ea50ee5212d06c29b7951dd416cb1.jpg  \n",
            " extracting: valid/images/jpqfy8q88ida1_jpg.rf.abd1edd9415cf8b6bf8784fc86cc6284.jpg  \n",
            " extracting: valid/images/m2knm1yzssoa1_jpg.rf.b6db7a511184a827f8cd90eac03ab9eb.jpg  \n",
            " extracting: valid/images/mcen7bieo4aa1_jpg.rf.4bf7bcaacda7d7e400f20d56d7b9b5df.jpg  \n",
            " extracting: valid/images/mwhmvhum2fna1_jpg.rf.067f4d71a0ae2e039b091c7ae0f7d8dc.jpg  \n",
            " extracting: valid/images/mzrzg7i213ha1_jpg.rf.25504c343e5d57a926e3d6babe7da95a.jpg  \n",
            " extracting: valid/images/n3wwf4c9nuga1_jpg.rf.6a6bddd45b6352335c9ab238cfad3232.jpg  \n",
            " extracting: valid/images/ojlckqv73hma1_jpg.rf.8231ee02d3ae8b535547184484381809.jpg  \n",
            " extracting: valid/images/os57kt6qfyga1_jpg.rf.7ccfc3aa24e77eae65914c13096fb4ae.jpg  \n",
            " extracting: valid/images/qCnRlWJtDgPcBF2yEfAd3JwYOT9c6H180N_CQ4g3nxE_jpg.rf.ca0101a2adca7303959620cc53324263.jpg  \n",
            " extracting: valid/images/qp478jqt0zha1_jpg.rf.7a7b6570d576e7acf5b2eb44d92edc47.jpg  \n",
            " extracting: valid/images/rj794aeqtrba1_jpg.rf.0f5549bf08e6d6c91a5a4fd74a4633b1.jpg  \n",
            "  inflating: valid/labels/f3qb1vrj1yoa1_jpg.rf.de8ea50ee5212d06c29b7951dd416cb1.txt  \n",
            "  inflating: valid/labels/jpqfy8q88ida1_jpg.rf.abd1edd9415cf8b6bf8784fc86cc6284.txt  \n",
            "  inflating: valid/labels/m2knm1yzssoa1_jpg.rf.b6db7a511184a827f8cd90eac03ab9eb.txt  \n",
            "  inflating: valid/labels/mcen7bieo4aa1_jpg.rf.4bf7bcaacda7d7e400f20d56d7b9b5df.txt  \n",
            "  inflating: valid/labels/mwhmvhum2fna1_jpg.rf.067f4d71a0ae2e039b091c7ae0f7d8dc.txt  \n",
            "  inflating: valid/labels/mzrzg7i213ha1_jpg.rf.25504c343e5d57a926e3d6babe7da95a.txt  \n",
            "  inflating: valid/labels/n3wwf4c9nuga1_jpg.rf.6a6bddd45b6352335c9ab238cfad3232.txt  \n",
            "  inflating: valid/labels/ojlckqv73hma1_jpg.rf.8231ee02d3ae8b535547184484381809.txt  \n",
            "  inflating: valid/labels/os57kt6qfyga1_jpg.rf.7ccfc3aa24e77eae65914c13096fb4ae.txt  \n",
            "  inflating: valid/labels/qCnRlWJtDgPcBF2yEfAd3JwYOT9c6H180N_CQ4g3nxE_jpg.rf.ca0101a2adca7303959620cc53324263.txt  \n",
            "  inflating: valid/labels/qp478jqt0zha1_jpg.rf.7a7b6570d576e7acf5b2eb44d92edc47.txt  \n",
            "  inflating: valid/labels/rj794aeqtrba1_jpg.rf.0f5549bf08e6d6c91a5a4fd74a4633b1.txt  \n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   903  100   903    0     0   2767      0 --:--:-- --:--:-- --:--:--  2769\n",
            "100  741k  100  741k    0     0  1099k      0 --:--:-- --:--:-- --:--:-- 14.4M\n",
            "Archive:  roboflow.zip\n",
            "replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: README.dataset.txt      \n",
            "  inflating: README.roboflow.txt     \n",
            "  inflating: data.yaml               \n",
            " extracting: test/images/003-jpg-4ttsoah9-ingestion-5f5cb77fd6-s2t7k_jpg.rf.4dd5a18b0b54a5e3acba7daea9093bcb.jpg  \n",
            " extracting: test/images/004_jpeg-jpg-4ttsoah6-ingestion-5f5cb77fd6-cblzb_jpg.rf.30fccca6cd6a5abf5c432cdaeb583fae.jpg  \n",
            " extracting: test/images/099-jpg-4ttsob0o-ingestion-5f5cb77fd6-cblzb_jpg.rf.723a820acefbaf5e3341a89a4e1148e2.jpg  \n",
            " extracting: test/images/142_png-jpg-4tts2ngq-ingestion-5f5cb77fd6-cblzb_jpg.rf.d724e5fe3cd3aaa619dc7ce151e095af.jpg  \n",
            "  inflating: test/labels/003-jpg-4ttsoah9-ingestion-5f5cb77fd6-s2t7k_jpg.rf.4dd5a18b0b54a5e3acba7daea9093bcb.txt  \n",
            "  inflating: test/labels/004_jpeg-jpg-4ttsoah6-ingestion-5f5cb77fd6-cblzb_jpg.rf.30fccca6cd6a5abf5c432cdaeb583fae.txt  \n",
            "  inflating: test/labels/099-jpg-4ttsob0o-ingestion-5f5cb77fd6-cblzb_jpg.rf.723a820acefbaf5e3341a89a4e1148e2.txt  \n",
            " extracting: test/labels/142_png-jpg-4tts2ngq-ingestion-5f5cb77fd6-cblzb_jpg.rf.d724e5fe3cd3aaa619dc7ce151e095af.txt  \n",
            " extracting: train/images/002_jpeg-jpg-4ttsoah4-ingestion-5f5cb77fd6-hn7b5_jpg.rf.c777b767cc46ecf21182caac657bde17.jpg  \n",
            " extracting: train/images/010_jpeg-jpg-4ttsoahu-ingestion-5f5cb77fd6-hn7b5_jpg.rf.842d899dcc0e79205c390d7f16531a12.jpg  \n",
            " extracting: train/images/013-jpg-4ttsoai5-ingestion-5f5cb77fd6-s2t7k_jpg.rf.1b33642bb4dcfb2da9fb8904ee87a781.jpg  \n",
            " extracting: train/images/014-jpg-4ttsoaif-ingestion-5f5cb77fd6-hn7b5_jpg.rf.00d22f45cba99be39dbc8eef121bbdab.jpg  \n",
            " extracting: train/images/015-jpg-4ttsoaii-ingestion-5f5cb77fd6-cblzb_jpg.rf.018ee48deb65c548e2e0d6832fff2584.jpg  \n",
            " extracting: train/images/018-jpg-4ttsoain-ingestion-5f5cb77fd6-s2t7k_jpg.rf.2d6a4dbecd56646471815ab0b97ecf35.jpg  \n",
            " extracting: train/images/070-jpg-4ttsob5r-ingestion-5f5cb77fd6-s2t7k_jpg.rf.d3a5d8fc8f7cbcd0a6f2d6d2eaeff178.jpg  \n",
            " extracting: train/images/080_jpeg-jpg-4ttsoavg-ingestion-5f5cb77fd6-cblzb_jpg.rf.1d6267c946e1cfb6e08aa46812bd6530.jpg  \n",
            " extracting: train/images/082_jpeg-jpg-4ttsob6i-ingestion-5f5cb77fd6-s2t7k_jpg.rf.98c75ce49f0f511986f382a19278c31e.jpg  \n",
            " extracting: train/images/084_jpeg-jpg-4ttsob00-ingestion-5f5cb77fd6-hn7b5_jpg.rf.1475369e0e00027ddc4b5cd25fccdcc9.jpg  \n",
            " extracting: train/images/091_jpeg-jpg-4ttsob06-ingestion-5f5cb77fd6-cblzb_jpg.rf.3e1125259fd967177129d5d0e2cde68b.jpg  \n",
            " extracting: train/images/094_jpeg-jpg-4ttsob0c-ingestion-5f5cb77fd6-s2t7k_jpg.rf.ae14e4e748e7e6b73c7bc3d402546e9e.jpg  \n",
            " extracting: train/images/098_jpeg-jpg-4ttsob7b-ingestion-5f5cb77fd6-hn7b5_jpg.rf.f9dad9e234e62f65da3b6326b17e10f8.jpg  \n",
            " extracting: train/images/101_png-jpg-4tts71se-ingestion-5f5cb77fd6-hn7b5_jpg.rf.dfcbc0cbc80af5fc5eb03a1f958a9590.jpg  \n",
            " extracting: train/images/111_png-jpg-4tts2m49-ingestion-5f5cb77fd6-cblzb_jpg.rf.9ed61c31c2feb86ac310f3f0920d75ae.jpg  \n",
            " extracting: train/images/125_png-jpg-4tts2mke-ingestion-5f5cb77fd6-cblzb_jpg.rf.f6577932cbe1dbb6ba4c44cdb68b6e58.jpg  \n",
            " extracting: train/images/128_png-jpg-4tts2mrk-ingestion-5f5cb77fd6-s2t7k_jpg.rf.45ee10ed0b52583bdef777b0ab06adab.jpg  \n",
            " extracting: train/images/134_png-jpg-4tts2n4p-ingestion-5f5cb77fd6-hn7b5_jpg.rf.11b31286b86a8a482254c6f84e29bd50.jpg  \n",
            " extracting: train/images/14_png-jpg-4tts72lt-ingestion-5f5cb77fd6-s2t7k_jpg.rf.8cdd6109be82d427c10745bfd6ed2490.jpg  \n",
            " extracting: train/images/150_png-jpg-4tts2npk-ingestion-5f5cb77fd6-hn7b5_jpg.rf.ca734cd1b1ff049ffced467b216d2100.jpg  \n",
            " extracting: train/images/158_png-jpg-4tts2o4k-ingestion-5f5cb77fd6-cblzb_jpg.rf.c265d48bd19033e7738ac372cc0ccf64.jpg  \n",
            " extracting: train/images/174_png-jpg-4tts2oos-ingestion-5f5cb77fd6-s2t7k_jpg.rf.f6491e299eb2ccb2d6114ca0aa2c3d63.jpg  \n",
            " extracting: train/images/175_png-jpg-4tts7386-ingestion-5f5cb77fd6-hn7b5_jpg.rf.4346f5160a396d798c377cd4a0fadb62.jpg  \n",
            " extracting: train/images/176_png-jpg-4tts2p1c-ingestion-5f5cb77fd6-cblzb_jpg.rf.c4001076db8fea22be9409c117ccf316.jpg  \n",
            " extracting: train/images/177_png-jpg-4tts2p23-ingestion-5f5cb77fd6-hn7b5_jpg.rf.e8ca194f9facd0e01a9e7a5e36f32942.jpg  \n",
            " extracting: train/images/1_png-jpg-4tts2pt7-ingestion-5f5cb77fd6-cblzb_jpg.rf.40e9256bcf1c4c136f0771834142d25f.jpg  \n",
            " extracting: train/images/201_png-jpg-4tts2puv-ingestion-5f5cb77fd6-s2t7k_jpg.rf.2f7ca54585fdac565db31bb5a0762586.jpg  \n",
            " extracting: train/images/202_png-jpg-4tts2q4s-ingestion-5f5cb77fd6-hn7b5_jpg.rf.dc6c3dff3361899c737e5a03f03a9812.jpg  \n",
            " extracting: train/images/208_png-jpg-4tts7411-ingestion-5f5cb77fd6-hn7b5_jpg.rf.b6b98472e739de5c24c75c228a5d18d3.jpg  \n",
            " extracting: train/labels/002_jpeg-jpg-4ttsoah4-ingestion-5f5cb77fd6-hn7b5_jpg.rf.c777b767cc46ecf21182caac657bde17.txt  \n",
            "  inflating: train/labels/010_jpeg-jpg-4ttsoahu-ingestion-5f5cb77fd6-hn7b5_jpg.rf.842d899dcc0e79205c390d7f16531a12.txt  \n",
            "  inflating: train/labels/013-jpg-4ttsoai5-ingestion-5f5cb77fd6-s2t7k_jpg.rf.1b33642bb4dcfb2da9fb8904ee87a781.txt  \n",
            "  inflating: train/labels/014-jpg-4ttsoaif-ingestion-5f5cb77fd6-hn7b5_jpg.rf.00d22f45cba99be39dbc8eef121bbdab.txt  \n",
            "  inflating: train/labels/015-jpg-4ttsoaii-ingestion-5f5cb77fd6-cblzb_jpg.rf.018ee48deb65c548e2e0d6832fff2584.txt  \n",
            " extracting: train/labels/018-jpg-4ttsoain-ingestion-5f5cb77fd6-s2t7k_jpg.rf.2d6a4dbecd56646471815ab0b97ecf35.txt  \n",
            " extracting: train/labels/070-jpg-4ttsob5r-ingestion-5f5cb77fd6-s2t7k_jpg.rf.d3a5d8fc8f7cbcd0a6f2d6d2eaeff178.txt  \n",
            "  inflating: train/labels/080_jpeg-jpg-4ttsoavg-ingestion-5f5cb77fd6-cblzb_jpg.rf.1d6267c946e1cfb6e08aa46812bd6530.txt  \n",
            "  inflating: train/labels/082_jpeg-jpg-4ttsob6i-ingestion-5f5cb77fd6-s2t7k_jpg.rf.98c75ce49f0f511986f382a19278c31e.txt  \n",
            "  inflating: train/labels/084_jpeg-jpg-4ttsob00-ingestion-5f5cb77fd6-hn7b5_jpg.rf.1475369e0e00027ddc4b5cd25fccdcc9.txt  \n",
            "  inflating: train/labels/091_jpeg-jpg-4ttsob06-ingestion-5f5cb77fd6-cblzb_jpg.rf.3e1125259fd967177129d5d0e2cde68b.txt  \n",
            "  inflating: train/labels/094_jpeg-jpg-4ttsob0c-ingestion-5f5cb77fd6-s2t7k_jpg.rf.ae14e4e748e7e6b73c7bc3d402546e9e.txt  \n",
            " extracting: train/labels/098_jpeg-jpg-4ttsob7b-ingestion-5f5cb77fd6-hn7b5_jpg.rf.f9dad9e234e62f65da3b6326b17e10f8.txt  \n",
            "  inflating: train/labels/101_png-jpg-4tts71se-ingestion-5f5cb77fd6-hn7b5_jpg.rf.dfcbc0cbc80af5fc5eb03a1f958a9590.txt  \n",
            "  inflating: train/labels/111_png-jpg-4tts2m49-ingestion-5f5cb77fd6-cblzb_jpg.rf.9ed61c31c2feb86ac310f3f0920d75ae.txt  \n",
            " extracting: train/labels/125_png-jpg-4tts2mke-ingestion-5f5cb77fd6-cblzb_jpg.rf.f6577932cbe1dbb6ba4c44cdb68b6e58.txt  \n",
            "  inflating: train/labels/128_png-jpg-4tts2mrk-ingestion-5f5cb77fd6-s2t7k_jpg.rf.45ee10ed0b52583bdef777b0ab06adab.txt  \n",
            "  inflating: train/labels/134_png-jpg-4tts2n4p-ingestion-5f5cb77fd6-hn7b5_jpg.rf.11b31286b86a8a482254c6f84e29bd50.txt  \n",
            "  inflating: train/labels/14_png-jpg-4tts72lt-ingestion-5f5cb77fd6-s2t7k_jpg.rf.8cdd6109be82d427c10745bfd6ed2490.txt  \n",
            "  inflating: train/labels/150_png-jpg-4tts2npk-ingestion-5f5cb77fd6-hn7b5_jpg.rf.ca734cd1b1ff049ffced467b216d2100.txt  \n",
            "  inflating: train/labels/158_png-jpg-4tts2o4k-ingestion-5f5cb77fd6-cblzb_jpg.rf.c265d48bd19033e7738ac372cc0ccf64.txt  \n",
            " extracting: train/labels/174_png-jpg-4tts2oos-ingestion-5f5cb77fd6-s2t7k_jpg.rf.f6491e299eb2ccb2d6114ca0aa2c3d63.txt  \n",
            "  inflating: train/labels/175_png-jpg-4tts7386-ingestion-5f5cb77fd6-hn7b5_jpg.rf.4346f5160a396d798c377cd4a0fadb62.txt  \n",
            "  inflating: train/labels/176_png-jpg-4tts2p1c-ingestion-5f5cb77fd6-cblzb_jpg.rf.c4001076db8fea22be9409c117ccf316.txt  \n",
            "  inflating: train/labels/177_png-jpg-4tts2p23-ingestion-5f5cb77fd6-hn7b5_jpg.rf.e8ca194f9facd0e01a9e7a5e36f32942.txt  \n",
            "  inflating: train/labels/1_png-jpg-4tts2pt7-ingestion-5f5cb77fd6-cblzb_jpg.rf.40e9256bcf1c4c136f0771834142d25f.txt  \n",
            "  inflating: train/labels/201_png-jpg-4tts2puv-ingestion-5f5cb77fd6-s2t7k_jpg.rf.2f7ca54585fdac565db31bb5a0762586.txt  \n",
            "  inflating: train/labels/202_png-jpg-4tts2q4s-ingestion-5f5cb77fd6-hn7b5_jpg.rf.dc6c3dff3361899c737e5a03f03a9812.txt  \n",
            "  inflating: train/labels/208_png-jpg-4tts7411-ingestion-5f5cb77fd6-hn7b5_jpg.rf.b6b98472e739de5c24c75c228a5d18d3.txt  \n",
            " extracting: valid/images/024-jpg-4ttsoaj4-ingestion-5f5cb77fd6-s2t7k_jpg.rf.c098729c65d3ea4bc8f52bc5be413a99.jpg  \n",
            " extracting: valid/images/039_jpeg-jpg-4ttsoajm-ingestion-5f5cb77fd6-s2t7k_jpg.rf.354eb722d6c5ba7113752c8b7242c1a9.jpg  \n",
            " extracting: valid/images/11_png-jpg-4tts2mds-ingestion-5f5cb77fd6-hn7b5_jpg.rf.d6d783cb604470ab5a0b1f5183392e60.jpg  \n",
            " extracting: valid/images/152_png-jpg-4tts2nvf-ingestion-5f5cb77fd6-hn7b5_jpg.rf.684050f2ab46ea667277e913d1b02eb5.jpg  \n",
            " extracting: valid/images/162_png-jpg-4tts72vg-ingestion-5f5cb77fd6-hn7b5_jpg.rf.feed8471467a84a575e0e3d6f3152068.jpg  \n",
            " extracting: valid/images/16_png-jpg-4tts7311-ingestion-5f5cb77fd6-s2t7k_jpg.rf.1efda67de12b7fff41e51ffd12e35059.jpg  \n",
            " extracting: valid/images/210_png-jpg-4tts2qgb-ingestion-5f5cb77fd6-s2t7k_jpg.rf.dc53deb5d88668b9e03b36c7d1337cae.jpg  \n",
            " extracting: valid/images/215_png-jpg-4tts2qv8-ingestion-5f5cb77fd6-s2t7k_jpg.rf.561f17a038b3cb0c21d5a7adb3fddbd2.jpg  \n",
            "  inflating: valid/labels/024-jpg-4ttsoaj4-ingestion-5f5cb77fd6-s2t7k_jpg.rf.c098729c65d3ea4bc8f52bc5be413a99.txt  \n",
            "  inflating: valid/labels/039_jpeg-jpg-4ttsoajm-ingestion-5f5cb77fd6-s2t7k_jpg.rf.354eb722d6c5ba7113752c8b7242c1a9.txt  \n",
            "  inflating: valid/labels/11_png-jpg-4tts2mds-ingestion-5f5cb77fd6-hn7b5_jpg.rf.d6d783cb604470ab5a0b1f5183392e60.txt  \n",
            " extracting: valid/labels/152_png-jpg-4tts2nvf-ingestion-5f5cb77fd6-hn7b5_jpg.rf.684050f2ab46ea667277e913d1b02eb5.txt  \n",
            "  inflating: valid/labels/162_png-jpg-4tts72vg-ingestion-5f5cb77fd6-hn7b5_jpg.rf.feed8471467a84a575e0e3d6f3152068.txt  \n",
            "  inflating: valid/labels/16_png-jpg-4tts7311-ingestion-5f5cb77fd6-s2t7k_jpg.rf.1efda67de12b7fff41e51ffd12e35059.txt  \n",
            "  inflating: valid/labels/210_png-jpg-4tts2qgb-ingestion-5f5cb77fd6-s2t7k_jpg.rf.dc53deb5d88668b9e03b36c7d1337cae.txt  \n",
            "  inflating: valid/labels/215_png-jpg-4tts2qv8-ingestion-5f5cb77fd6-s2t7k_jpg.rf.561f17a038b3cb0c21d5a7adb3fddbd2.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d57c58d5",
        "outputId": "3a7f5a73-2bf8-4885-9d1c-40cc91abc983"
      },
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "print(\"YOLOv8n model loaded successfully.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FICnkCkqsdx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IH3AoeOosdtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4dwGsCc-sdpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHbh3aU2s2SY",
        "outputId": "a6b7c706-e1a5-46ea-a7c7-cd23a0358192"
      },
      "source": [
        "import os\n",
        "\n",
        "onnx_model_path = 'yolov8n.onnx'\n",
        "\n",
        "if not os.path.exists(onnx_model_path):\n",
        "    print(f\"'{onnx_model_path}' not found. Re-exporting the model.\")\n",
        "    # Re-export the model using the correct argument for filename/name\n",
        "    # Assuming the 'model' object from previous steps is still available and loaded\n",
        "    model.export(format='onnx', name='yolov8n.onnx')\n",
        "    print(\"YOLOv8n model re-exported to ONNX format.\")\n",
        "else:\n",
        "    print(f\"'{onnx_model_path}' found. Proceeding with quantization.\")\n",
        "\n",
        "# Now attempt to quantize the model again\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "quantized_model_path = 'yolov8n_quantized.onnx'\n",
        "\n",
        "quantize_dynamic(\n",
        "    model_input=onnx_model_path,\n",
        "    model_output=quantized_model_path,\n",
        "    weight_type=QuantType.QUInt8\n",
        ")\n",
        "\n",
        "print(f\"YOLOv8n model quantized and saved to {quantized_model_path}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'yolov8n.onnx' found. Proceeding with quantization.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n model quantized and saved to yolov8n_quantized.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5e57be9",
        "outputId": "88f94114-c5b4-4710-8686-add434b48754"
      },
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "import os\n",
        "\n",
        "# Define the path to the original ONNX model (assuming it's in the current directory)\n",
        "onnx_model_path = 'yolov8n.onnx'\n",
        "\n",
        "# Define the target path for the quantized model in Google Drive\n",
        "quantized_model_dir = '/content/drive/My Drive/DS/trained_models'\n",
        "quantized_model_path = os.path.join(quantized_model_dir, 'yolov8n_quantized.onnx')\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "os.makedirs(quantized_model_dir, exist_ok=True)\n",
        "\n",
        "quantize_dynamic(\n",
        "    model_input=onnx_model_path,\n",
        "    model_output=quantized_model_path,\n",
        "    weight_type=QuantType.QUInt8\n",
        ")\n",
        "\n",
        "print(f\"YOLOv8n model quantized and saved to {quantized_model_path}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n model quantized and saved to /content/drive/My Drive/DS/trained_models/yolov8n_quantized.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QF19hnr9DFIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47a2e35",
        "outputId": "051694f9-6ae4-4731-8844-25ded55a3908"
      },
      "source": [
        "from easyocr import Reader\n",
        "\n",
        "# Initialize the EasyOCR Reader for English, configured for CPU usage\n",
        "reader = Reader(['en'], gpu=False)\n",
        "\n",
        "print(\"EasyOCR Reader initialized for English and configured for CPU usage.\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EasyOCR Reader initialized for English and configured for CPU usage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd7d1758"
      },
      "source": [
        " function to perform OCR on a cropped image using the initialized EasyOCR reader.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33749c5e",
        "outputId": "fbdd3871-6007-4dc5-decc-4f83933433f9"
      },
      "source": [
        "def extract_text_from_crop(image_crop):\n",
        "  \"\"\"\n",
        "  Extracts text from a cropped image using EasyOCR.\n",
        "\n",
        "  Args:\n",
        "    image_crop: A NumPy array or PIL Image representing the cropped image.\n",
        "\n",
        "  Returns:\n",
        "    A string containing the extracted text, or an empty string if no text is found.\n",
        "  \"\"\"\n",
        "  # Use the globally initialized EasyOCR reader\n",
        "  results = reader.readtext(image_crop)\n",
        "\n",
        "  extracted_text = \"\"\n",
        "  if results:\n",
        "    # EasyOCR output is a list of tuples: (bbox, text, confidence)\n",
        "    # Concatenate the recognized text from all detected regions\n",
        "    extracted_text = \" \".join([text for (bbox, text, confidence) in results])\n",
        "\n",
        "  return extracted_text\n",
        "\n",
        "print(\"Function 'extract_text_from_crop' defined.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'extract_text_from_crop' defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2bc3dc3e",
        "outputId": "f71d7762-1f9b-4ffd-c770-0c5c9e38e145"
      },
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the pre-trained YOLOv8n model\n",
        "# Assuming the model object is not available in the current session,\n",
        "# we reload it. If 'model' is already defined and loaded, this line\n",
        "# can be skipped.\n",
        "try:\n",
        "    model\n",
        "except NameError:\n",
        "    print(\"Loading YOLOv8n model...\")\n",
        "    model = YOLO('yolov8n.pt')\n",
        "    print(\"YOLOv8n model loaded.\")\n",
        "\n",
        "# --- Fine-tune the model ---\n",
        "# You need to have your dataset in the correct YOLO format (images and labels)\n",
        "# and a data.yaml configuration file.\n",
        "# Assuming the dataset was downloaded and unzipped in a previous step,\n",
        "# the data.yaml file should be in the root of the unzipped directory.\n",
        "# Update the 'data' argument with the path to your data.yaml file.\n",
        "\n",
        "# Example: If data.yaml is in a folder named 'dataset' in the current directory\n",
        "# data_config_path = 'dataset/data.yaml'\n",
        "\n",
        "# Based on previous steps, your data.yaml might be in the current directory\n",
        "data_config_path = 'data.yaml' # Adjust this path if your data.yaml is elsewhere\n",
        "\n",
        "print(f\"Starting fine-tuning with data config: {data_config_path}\")\n",
        "\n",
        "# Train the model\n",
        "# Specify the number of epochs, image size, and device ('cpu')\n",
        "# Adjust epochs and img size based on your dataset and desired training time\n",
        "results = model.train(data=data_config_path, epochs=10, imgsz=640, device='cpu') # Reduced epochs for faster training\n",
        "\n",
        "print(\"\\nFine-tuning completed.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning with data config: data.yaml\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.3.0+cpu CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train22, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 938.2±395.6 MB/s, size: 113.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels.cache... 125 images, 0 backgrounds, 0 corrupt: 100%|██████████| 125/125 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 96, len(boxes) = 129. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 581.2±275.2 MB/s, size: 36.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|██████████| 20/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 12, len(boxes) = 20. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train22/labels.jpg... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train22\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/8 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-51-3892405801.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Specify the number of epochs, image size, and device ('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Adjust epochs and img size based on your dataset and desired training time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_config_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reduced epochs for faster training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFine-tuning completed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;34m\"\"\"Apply sequential pooling operations to input and return concatenated feature maps.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;34m\"\"\"Apply sequential pooling operations to input and return concatenated feature maps.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    165\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                             return_indices=self.return_indices)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ad61f63",
        "outputId": "505221d8-a4c5-4c26-acff-0cea7dad7cf8"
      },
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Define the path to the fine-tuned model weights\n",
        "# Assuming the best model is saved in the default run directory from the previous training cell\n",
        "# Check the output of the training cell to confirm the exact path if needed.\n",
        "fine_tuned_model_path = 'runs/detect/train2/weights/best.pt' # Update 'train2' if your run directory name was different\n",
        "\n",
        "# Check if the fine-tuned model exists\n",
        "if not os.path.exists(fine_tuned_model_path):\n",
        "    print(f\"Fine-tuned model not found at: {fine_tuned_model_path}\")\n",
        "    print(\"Please ensure the training completed successfully and check the output of the training cell for the correct path.\")\n",
        "else:\n",
        "    # Load the fine-tuned YOLOv8 model\n",
        "    try:\n",
        "        fine_tuned_model = YOLO(fine_tuned_model_path)\n",
        "        print(f\"Fine-tuned model loaded successfully from {fine_tuned_model_path}\")\n",
        "\n",
        "        # Find a sample image path to test detection\n",
        "        # Using the same logic as before, prioritizing dataset directories then manual path\n",
        "        sample_image_path = None\n",
        "        possible_image_dirs = ['./test/images', './train/images', './valid/images']\n",
        "        for img_dir in possible_image_dirs:\n",
        "            if os.path.exists(img_dir):\n",
        "                images = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                if images:\n",
        "                    sample_image_path = os.path.join(img_dir, images[0])\n",
        "                    break\n",
        "\n",
        "        # If a sample image was not found in the dataset directories, try the manually specified path that worked before\n",
        "        if sample_image_path is None:\n",
        "            manual_sample_image_path = 'drive/MyDrive/Captureww.PNG' # Use the path that worked previously\n",
        "            if os.path.exists(manual_sample_image_path):\n",
        "                sample_image_path = manual_sample_image_path\n",
        "                print(f\"Using manually specified sample image: {sample_image_path}\")\n",
        "            else:\n",
        "                print(\"Could not find a sample image in dataset directories or the manually specified path.\")\n",
        "                print(\"Please ensure an image exists in one of these locations or update the path.\")\n",
        "\n",
        "        if sample_image_path:\n",
        "            print(f\"Running inference with fine-tuned model on: {sample_image_path}\")\n",
        "\n",
        "            # Load the sample image\n",
        "            img = cv2.imread(sample_image_path)\n",
        "            if img is None:\n",
        "                print(f\"Failed to load image from {sample_image_path}. Skipping inference.\")\n",
        "            else:\n",
        "                # Run inference\n",
        "                start_time = time.time()\n",
        "                # Use the predict method of the loaded YOLO model\n",
        "                # Setting conf=0.25 as in previous steps, device='cpu' for CPU inference\n",
        "                results = fine_tuned_model.predict(img, save=False, imgsz=640, conf=0.25, device='cpu')\n",
        "                end_time = time.time()\n",
        "                inference_time = end_time - start_time\n",
        "                print(f\"Inference with fine-tuned model completed in {inference_time:.4f} seconds.\")\n",
        "\n",
        "                # Process results\n",
        "                # The 'results' object from model.predict is a list of Results objects, one per image\n",
        "                if results:\n",
        "                    # Assuming batch size 1, get the results for the first image\n",
        "                    detections = results[0] # ultralytics.engine.results.Results object\n",
        "\n",
        "                    print(f\"\\nDetected objects (filtered by confidence {detections.boxes.conf.min() if detections.boxes and len(detections.boxes) > 0 else 0:.2f}):\")\n",
        "                    # Print detected boxes, classes, and confidence scores\n",
        "                    if detections.boxes is not None and len(detections.boxes) > 0:\n",
        "                        for box in detections.boxes:\n",
        "                            # box.xyxy: [x1, y1, x2, y2] in original image coordinates\n",
        "                            # box.conf: confidence score\n",
        "                            # box.cls: class index (as a tensor)\n",
        "                            x1, y1, x2, y2 = [int(coord) for coord in box.xyxy[0].tolist()]\n",
        "                            confidence = box.conf[0].item()\n",
        "                            class_id = int(box.cls[0].item())\n",
        "\n",
        "                            # You might need to load your data.yaml to map class_id to class name\n",
        "                            # For now, we print the class ID\n",
        "                            print(f\"  Box: [{x1}, {y1}, {x2}, {y2}], Confidence: {confidence:.2f}, Class ID: {class_id}\")\n",
        "\n",
        "                        # --- IMPORTANT: Replace 0 with the actual class ID for 'license-plate' from your data.yaml ---\n",
        "                        # Assuming class_id 0 is 'license-plate' based on common datasets\n",
        "                        # You should verify this from your data.yaml file used for training.\n",
        "                        LICENSE_PLATE_CLASS_ID = 0 # <--- !!! SET THIS TO YOUR LICENSE PLATE CLASS ID !!!\n",
        "\n",
        "                        license_plate_detections = [box for box in detections.boxes if int(box.cls[0].item()) == LICENSE_PLATE_CLASS_ID]\n",
        "\n",
        "                        if license_plate_detections:\n",
        "                            print(f\"\\nFound {len(license_plate_detections)} license plate detections.\")\n",
        "                            # Now you can iterate through license_plate_detections and pass the cropped images\n",
        "                            # to your extract_text_from_crop function for OCR.\n",
        "                            print(\"License plates detected. Ready for OCR integration.\")\n",
        "                        else:\n",
        "                            print(\"No license plate detections found with the specified class ID and confidence.\")\n",
        "\n",
        "                    else:\n",
        "                        print(\"No objects detected above the confidence threshold.\")\n",
        "                else:\n",
        "                    print(\"No inference results obtained.\")\n",
        "        else:\n",
        "            print(\"Skipping inference as no sample image was found.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or running inference with fine-tuned model: {e}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model loaded successfully from runs/detect/train2/weights/best.pt\n",
            "Running inference with fine-tuned model on: ./test/images/g1p35c8s49na1_jpg.rf.3fbaea5b617329c88b446a561cbbe7cf.jpg\n",
            "\n",
            "0: 640x640 1 plate, 344.0ms\n",
            "Speed: 11.9ms preprocess, 344.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Inference with fine-tuned model completed in 0.5883 seconds.\n",
            "\n",
            "Detected objects (filtered by confidence 0.30):\n",
            "  Box: [208, 282, 390, 442], Confidence: 0.30, Class ID: 0\n",
            "\n",
            "Found 1 license plate detections.\n",
            "License plates detected. Ready for OCR integration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ecbadaf",
        "outputId": "c4532ef6-0f5c-4b51-a13e-89a8d381e036"
      },
      "source": [
        "# Assuming 'fine_tuned_model' is loaded and 'sample_image_path' is defined from the previous cell (1ad61f63)\n",
        "# Assuming 'extract_text_from_crop' function is defined (cell 33749c5e)\n",
        "# Assuming 'reader' is initialized (cell 5b52842d)\n",
        "\n",
        "if 'fine_tuned_model' in locals() and 'sample_image_path' in locals() and os.path.exists(sample_image_path):\n",
        "    print(f\"Processing sample image with fine-tuned model and OCR: {sample_image_path}\")\n",
        "\n",
        "    # Load the original image again for cropping\n",
        "    original_image_for_ocr = cv2.imread(sample_image_path)\n",
        "    if original_image_for_ocr is None:\n",
        "        print(f\"Failed to load image from {sample_image_path} for OCR. Skipping OCR.\")\n",
        "    else:\n",
        "        # Run inference with the fine-tuned model to get the latest detections\n",
        "        # Use the same settings as the previous inference test\n",
        "        results = fine_tuned_model.predict(original_image_for_ocr, save=False, imgsz=640, conf=0.25, device='cpu')\n",
        "\n",
        "        # Process results and perform OCR\n",
        "        if results:\n",
        "            detections = results[0] # Get results for the first image\n",
        "\n",
        "            license_plate_found_in_inference = False\n",
        "            if detections.boxes is not None and len(detections.boxes) > 0:\n",
        "                 # --- IMPORTANT: Replace 0 with the actual class ID for 'license-plate' from your data.yaml ---\n",
        "                # Assuming class_id 0 is 'license-plate' based on common datasets\n",
        "                # You should verify this from your data.yaml file used for training.\n",
        "                LICENSE_PLATE_CLASS_ID = 0 # <--- !!! SET THIS TO YOUR LICENSE PLATE CLASS ID !!!\n",
        "\n",
        "                license_plate_detections = [box for box in detections.boxes if int(box.cls[0].item()) == LICENSE_PLATE_CLASS_ID]\n",
        "\n",
        "                if license_plate_detections:\n",
        "                    license_plate_found_in_inference = True\n",
        "                    print(f\"\\nFound {len(license_plate_detections)} license plate detections for OCR processing.\")\n",
        "\n",
        "                    for i, box in enumerate(license_plate_detections):\n",
        "                        # box.xyxy: [x1, y1, x2, y2] in original image coordinates\n",
        "                        x1, y1, x2, y2 = [int(coord) for coord in box.xyxy[0].tolist()]\n",
        "                        confidence = box.conf[0].item()\n",
        "\n",
        "                        print(f\"Processing detected license plate {i+1}: Box [{x1}, {y1}, {x2}, {y2}], Confidence: {confidence:.2f}\")\n",
        "\n",
        "                        # Clamp coordinates to image boundaries\n",
        "                        img_height, img_width = original_image_for_ocr.shape[:2]\n",
        "                        x1 = max(0, x1)\n",
        "                        y1 = max(0, y1)\n",
        "                        x2 = min(img_width - 1, x2)\n",
        "                        y2 = min(img_height - 1, y2)\n",
        "\n",
        "                        # Crop the license plate region\n",
        "                        if x1 < x2 and y1 < y2:\n",
        "                            cropped_plate_image = original_image_for_ocr[y1:y2, x1:x2]\n",
        "\n",
        "                            if cropped_plate_image.shape[0] > 0 and cropped_plate_image.shape[1] > 0:\n",
        "                                # Perform OCR on the cropped plate\n",
        "                                print(\"  Starting OCR on cropped license plate...\")\n",
        "                                start_time_ocr = time.time()\n",
        "                                # --- Apply Pre-processing before OCR ---\n",
        "                                # 1. Grayscale Conversion\n",
        "                                gray_image_ocr = cv2.cvtColor(cropped_plate_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                                # 2. Binarization (using Otsu's method)\n",
        "                                _, binary_image_ocr = cv2.threshold(gray_image_ocr, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "                                # Use the pre-processed image for OCR\n",
        "                                ocr_input_image = binary_image_ocr\n",
        "\n",
        "                                extracted_text = extract_text_from_crop(ocr_input_image) # Call the OCR function\n",
        "                                end_time_ocr = time.time()\n",
        "                                ocr_time = end_time_ocr - start_time_ocr\n",
        "                                print(f\"  Extracted Text: '{extracted_text}'\")\n",
        "                                print(f\"  Time taken for OCR: {ocr_time:.4f} seconds\")\n",
        "                            else:\n",
        "                                print(\"  Cropped license plate image is empty or invalid. Skipping OCR.\")\n",
        "                        else:\n",
        "                            print(\"  Invalid bounding box for cropping license plate. Skipping OCR.\")\n",
        "\n",
        "            if not license_plate_found_in_inference:\n",
        "                 print(\"No license plate detections found above the confidence threshold in the inference results.\")\n",
        "\n",
        "        else:\n",
        "            print(\"No inference results obtained from the fine-tuned model.\")\n",
        "\n",
        "else:\n",
        "    print(\"Fine-tuned model or sample image not available. Skipping integrated inference and OCR.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sample image with fine-tuned model and OCR: ./test/images/g1p35c8s49na1_jpg.rf.3fbaea5b617329c88b446a561cbbe7cf.jpg\n",
            "\n",
            "0: 640x640 1 plate, 247.8ms\n",
            "Speed: 5.9ms preprocess, 247.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "Found 1 license plate detections for OCR processing.\n",
            "Processing detected license plate 1: Box [208, 282, 390, 442], Confidence: 0.30\n",
            "  Starting OCR on cropped license plate...\n",
            "  Extracted Text: 'IHHIEBH Mc noNick'\n",
            "  Time taken for OCR: 0.8290 seconds\n"
          ]
        }
      ]
    }
  ]
}